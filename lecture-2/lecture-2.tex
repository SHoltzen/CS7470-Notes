\documentclass{tufte-handout}

\title{Propositional Probability I: Syntax \& semantics\thanks{CS7470 Fall 2023: Foundations of Probabilistic Programming.}}

\author[]{Steven Holtzen\\s.holtzen@northeastern.edu}

%\date{28 March 2010} % without \date command, current date is supplied

%\geometry{showframe} % display margins for debugging page layout
\input{../header.tex}

\begin{document}
\maketitle% this prints the handout title, author, and date
\marginnote{``Programming languages are languages, a means of expressing
computations in a form comprehensible to both people and machines.'' \citet{harper2016practical}}


The goal of these next 3 lectures is to build our our first ``probabilistic programming
language''. I put that in quotes because it is not going to look like a typical
programming language like C or Java. We will build our way up to programming
languages that look more familiar to you, but today we will encounter a ``baby''
PPL that is nonetheless surprisingly useful. That baby PPL will be based on
\emph{propositional logic}. Along the way, we will see the basics of
(discrete) probability that we will need for the first part of the course.

\section{Probability}
\marginnote{``Whereas truth values in logic characterize the formulas under
 discussion, uncertainty characterizes \emph{invisible}
 facts.''
 \citet{pearl1988probabilistic}
}
\marginnote{The formal notion of probability 
used here was introduced by Kolmogorov; see \citet{kolmogorov2018foundations}. 
There have been many introductions and interesting discussions of formal 
notions of probability over the years; see \citet{jaynes2003probability} for an 
interesting discussion. I also like the discussion in \citet[Chapter 8]{graham1989concrete}}
We begin with some formal definitions from \emph{probability}, which will give us a formal basis 
for describing relative degrees of certainty we give to facts about the world:
\begin{definition}
    Let $\Omega$ be a set called the \defn{sample space}; assume that $|\Omega|$ is at most 
    countably-infinite; we will deal with larger classes of sample spaces later on.
    A function $\Pr : \Omega \rightarrow [0,1]$ is called a \defn{probability measure on $\Omega$} 
    if it satisfies that $\sum_{\omega \in \Omega} \Pr(\omega) = 1$.
    The pair ($\Omega, \Pr)$ is called a \defn{discrete probability space}.
\end{definition}

For example, a sample space could be the set of all pairs of six-sided dice rolls:
\begin{align*}
    \Omega_{dice} = \{ (1~1), (1~2), (1~3), \cdots, (6~6)\}
\end{align*}
Then, we would assign a \emph{uniform probability distribution} over all dice
rolls:
\begin{align*}
    \text{For all } \omega \in \Omega_{dice}, \Pr_{dice}(\omega) = 1/36.
\end{align*}
Then, we have a probability space $(\Omega_{dice}, \Pr_{dice})$.
Or, continuing with our propositional example,
Table~\ref{tbl:simple} gives an example of a probability table that describes a
probability distribution over the sample space of instances for a 2-variable
propositional sentence involving variables $x$ and $y$.

\begin{table}
    \centering
 \begin{tabular}{c||c}
    \toprule
    $\omega$ & $\Pr(\omega)$ \\
    \midrule 
    $(\true, \true)$ & 0.1 \\ 
    $(\true, \false)$ & 0.2 \\ 
    $(\false, \true)$ & 0.3 \\ 
    $(\false, \false)$ & 0.4 \\ 
    \bottomrule
\end{tabular}
\caption{A simple probability table.}
\label{tbl:simple}
\end{table}

\begin{marginfigure}
    \begin{tikzpicture}
        \draw[fill=gray] (0,0) circle (1) (0,1)  node [text=black,above] {$A$};
            %   (1,0) circle (1) (1,1)  node [text=black,above] {$B$}
        \draw (-2,-2) rectangle (3,2) node [text=black,above] {$\Omega$};
        \end{tikzpicture}
        \caption{An event is a subset of the sample space $\Omega$. Here, the event $A$ 
        is visualized using a Venn-diagram as a subset of the sample space $\Omega$.}
\end{marginfigure}

There is a substantial amount of standard notation for working with probability spaces, 
which we briefly review here; a nice summary resource is \citet[Chapter 3]{darwiche2009modeling}.
An \defn{event} is a subset of the sample space $E \subseteq \Omega$. We define
the probability of an event to be the sum total of all the elements of $\Omega$ that 
are contained in the event:
\begin{align}
    \Pr(E) \triangleq \sum_{\omega \in E} \Pr(\omega).
\end{align}
Continuing with our above example, $\Pr(\{(d_1, d_2) \mid d_1 = 1\})$ is 1/6.

Typically in probability we work with quantities that are derived from the sample space; 
these are called random variables.
Formally, a \defn{random variable} is a map out of the sample space. For instance, we can
define a random variable $S : \Omega_{dice} \rightarrow \mathbb{N}$ to be to sum two dice rolls
$\pi_1$ to be the first die's value, and $\pi_2$ to be the second,where
$\mathbb{N}$ is the set of natural numbers:
\begin{align}
    S((d_1, d_2)) = d_1 + d_2, \quad \pi_1((d_1, d_2)) = d_1, \quad \pi_2((d_1, d_2)) = d_2.
    \label{eq:rvs}
\end{align}

A random variable induces a probability distribution on its co-domain. For a
random variable $X : \Omega \rightarrow D$ acting on a probability space
$(\Omega, \Pr)$, we can compute the probability of a particular element $d \in
D$ by computing the total probability mass in $\Omega$ that is mapped to $d$,
i.e.:\marginnote{Another way of interpreting this notation is that the event $X = x$
is the set of elements of $\Omega$ such that $X(\omega) = x$.}
\begin{align}
    \Pr(X = x) \triangleq \Pr(X^{-1}(x)) = \sum_{\{\omega \in \Omega \mid X(\omega) = x\}} \Pr(\omega).
\end{align}

Given two random variables $X$ and $Y$ defined on the same sample space
$\Omega$, we quite often want to characterize their joint behavior. The 
\defn{joint probability distribution} of two random variables relates them:
\begin{align}
    \Pr(X=x, Y=y) \triangleq \Pr(X^{-1}(x) \cap Y^{-1}(y)).
\end{align}


For example, returning to the dice situation above, we can compute the 
joint probability for any particular pair of dice rolls:
\begin{align*}
    \Pr(\pi_1 = 1, \pi_2 = 1) = \sum_{\{(d_1, d_2) \in \Omega_{dice} \mid d_1 = 1, d_2 = 1 \}} \Pr((d_1, d_2)) = 1/36.
\end{align*}

Given a joint probability distribution $\Pr(X, Y)$, it is often useful to ``forget'' 
one of the random variables and consider only the distribution over the remaining 
variables. This is called the \defn{marginal probability}, and it is computed by summing 
over all possible values the random variable can take on. Concretely, the
marginal probability of $X$ is given by ``summing out'' $Y$:
\begin{align}
    \Pr(X = x) \triangleq \sum_{y} \Pr(X=x, Y=y)
    \label{eq:marg}
\end{align}

\newthought{One of the most common operations} one performs in probability is
\emph{conditioning}: computing the probability that some event happens
\emph{given an observation} that some other event has occurred. For instance,
one might ask, ``what is the probability of that the sum of a pair of dice rolls
is even given that one of them is 1''? Formally, these questions are instances
of \emph{conditional probability}; notationally, the above question would be 
written as $\Pr( S \text { is even} \mid \pi_1 = 1)$; the bar separates two
events, and is read ``given''.


\begin{marginfigure}
    \begin{tikzpicture}[fill=gray]
    % left hand
    \scope
    \clip (-2,-2) rectangle (2,2)
          (1,0) circle (1);
    \fill (0,0) circle (1);
    \endscope
    % right hand
    \scope
    \clip (-2,-2) rectangle (2,2)
          (0,0) circle (1);
    \fill (1,0) circle (1);
    \endscope
    % outline
    \draw (0.5, 0) node {$A \cap B$};
    \draw (0,0) circle (1) (0,1)  node [text=black,above] {$A$}
          (1,0) circle (1) (1,1)  node [text=black,above] {$B$}
          (-2,-2) rectangle (3,2) node [text=black,above] {$\Omega$};
    \end{tikzpicture}
    \caption{It is useful to visualize set intersection when understanding conditioning. 
    By definition, $\Pr(A \mid B) = \Pr(A \cap B)/\Pr(B)$. Intuitively, this corresponds to 
    considering the event at the intersection of these two events, and \emph{re-normalizing}
    that probability based on the viewpoint of the restricted new sample space $B$.
    }
\end{marginfigure}
Given a joint probability distribution $\Pr(X, Y)$, we define the \defn{conditional probability}
of $X$ given $Y$ is:
\begin{align}
    \Pr(X=x \mid Y = y) \triangleq \frac{\Pr(X = x, Y = y)}{\Pr(Y = y)}.
    \label{eq:cond}
\end{align}
There are a number of relationships between these quantities that are commonly used.
One is the law of total probability, which can be derived by
combining equations (\ref{eq:cond}) and (\ref{eq:marg}):
\begin{align}
    \Pr(X=x) = \sum_y \Pr(X = x \mid Y = y)\Pr(y).
\end{align}
It is sometimes the case that conditioning on one random variable has no effect:
for instance, in our dice-roll example, observing the value of the first die
tells you nothing about the value of the second die. Formally, we say two 
random variables $X$ and $Y$ are \defn{independent}, written $X \indep Y$, if 
the following holds:
\begin{align*}
    X \indep Y \text{ if for all }x, y \text{ it holds that } \Pr(X=x \mid Y=y) = \Pr(X = x).
\end{align*}


\begin{exercise}[$\star$]
    See Equation~\ref{eq:rvs}.  What is $\Pr(S = 3 \mid \pi_1 = 1)$?
\end{exercise}

\begin{exercise}[$\star$]
    See Equation~\ref{eq:rvs}. Show that $S \not \indep \pi_1$ and $\pi_1 \indep \pi_2$. 
\end{exercise}

\begin{exercise}[$\star$]
    Let $X$ and $Y$ be random variables defined on the same sample space. Show 
    that, if $X \indep Y$, then $\Pr(X = x, Y = y) = \Pr(X = x) \times \Pr(Y = y)$.
\end{exercise}

\section{Probabilistic models}
One of our main goals in this class is to automate probabilistic reasoning on a
computer.  For this purpose, our discussion so far of probability has been too
abstract: we are told nothing about \emph{how} these various probabilistic
quantities can be computed, or how we can represent probability distributions to
the computer. The means of describing a distribution to a computer is called a
\defn{probabilistic model}; it is a data-structure. The simplest kind of
probabilistic model is a look-up table (or dictionary):
\begin{definition}
    A \defn{probability lookup table} $\mathcal{T}$ is a lookup-table that maps
    elements of the sample space $\omega \in \Omega$ to the probability of that
    element $\Pr(\omega)$. 
    Lookup tables support constant-time lookups.
\end{definition}

For instance, if we are given a discrete sample space with 4 
elements $\Omega = \{1, 2, 3, 4\}$, then we can represent this as 
a dictionary or look-up table:
\begin{align}
    \mathcal{T} = [1 \mapsto 0.1, 2 \mapsto 0.2, 3 \mapsto 0.3, 4 \mapsto 0.4],
\end{align}
The \defn{size} is the amount of memory required to represent the model to the 
computer; it is denoted $|\cdot|$. In the case of a look-up table, the size is 
equal to $|\Omega|$.



\subsection{Querying}
Now that we have a concrete description of a probability distribution, we can
describe algorithms for automatically \emph{querying} for properties about these
representations. Different kinds of probabilistic models will support different 
kinds of queries, and have different complexity-theoretic properties of those queries. cWe have already seen the most basic kind of query: given some 
event $E \subseteq \Omega$, compute the probability of that event $\Pr(E)$. 
This immediately raises the question: how do we represent events? The most basic 
approach is a \defn{set-event}, which supports constant-time membership checks 
(i.e., given some event $\omega \in \Omega$, a set-event $E$ can answer the question 
of whether or not $\omega \in E$ in constant time).
Now, we can give an algorithm for computing the probability of a set-event for 
a particular probability look-up table:

\begin{algorithm}
    \caption{QueryEvent$_1$($\Pr, E)$}\label{alg:eventprob}
    \KwData{A probability look-up table $\Pr$; an set-event $E$}
    \KwResult{The probability of the event $\Pr(E)$}
    $a \leftarrow 0$\;
    \For{each $\omega \in \Omega$}{
        \lIf{$\omega \in E$}{$a \leftarrow a + \Pr(\omega)$}
    }
    \Return{a}
\end{algorithm}

What is the time-complexity of running QueryEvent$_1(\Pr, E)$? Since evaluating
$\Pr(\omega)$ and checking membership $\omega \in E$ are both constant time, the
overall time complexity is $|\Omega|$: the cost of iterating the outer loop from
Lines 2--4.  Is this an acceptable cost? Typically, \emph{no}! The size of the
sample space $\Omega$ is typically prohibitively large: it represents the set of
\emph{all} possibilities. 

This leads us to \emph{the fundamental design challenge of probabilistic modeling}.
We desire a \emph{concise} (i.e., small in representation size, for instance polynomial in $\log |\Omega|$) language for describing 
probability distributions and queries; ideally, this language is usable and interpretable 
by a user. Additionally, we desire we want our queries to be \emph{tractable}: when we 
compute the probability of an event (or perhaps some other kind of query), we want it to 
be as efficient as possible in the representation size. We will see that these two attributes,
tractability and conciseness, are in tension. In the case of lookup-table
distributions and set-events, queries are tractable -- they are typically linear $|\mathcal{T}|$,
but these representations are not concise: they are as large as the sample space.


\section{Propositional logic}

What is a good language for describing probability distributions that is an 
alternative to lookup-table distributions and set-events? Throughout the course 
we will slowly grow our vocabulary for describing these things, but for now we 
begin with a simple language for describing sets of possibilities: \emph{propositional logic}.

Propositional logic is a formal language and has two components: syntax and
semantics. The syntax tells us how to write valid statements in propositional
logic, and the semantics tell us how to interpret those statements. For example, we 
may wish to express the logical statement ``if it rains, then it is wet''. To do 
this, we will introduce two \defn{propositional variables} $r$ and $w$: $r$ is true 
if and only if it is raining, and $w$ is true if and only if it is wet. We can 
relate these two variables by using \defn{propositional connectives}. In the above example, 
we will use the \defn{implication connective} $r \Rightarrow w$, which states that if $r$ is 
true then so is $w$. 

We can summarize these connectives using the following grammar, which tells us how to form 
any \defn{propositional formula} $\varphi, \alpha,$ or $\beta$ in propositional
logic by combining propositional variables
(lower-case letters) with any of the standard propositional connectives (conjunction $land$, disjunction $\lor$, 
unary negation $\neg$, and bi-implication $\Leftrightarrow$):\sidenote{This style of grammar 
is often called Backus-Naur style.}
\begin{align}
    \varphi, \alpha, \beta ::= V \mid \true \mid \false \mid \neg \varphi \mid \alpha \land \beta \mid 
    \alpha \lor \beta \mid \alpha \Rightarrow \beta \mid \alpha \Leftrightarrow \beta 
    \mid (\alpha)
\end{align}

Using the above grammar, we can write down some more formulae, like
$(a \land b) \lor (c \land \neg d)$ and $(a \Leftrightarrow b) \land w$.

\subsection{Semantics of propositional logic}
We now know how to write down valid syntactic formulae in propositional logic, but 
we have not yet described what they \emph{mean}: how these formulae relate to the 
original quantities in the real world, and how to unambiguously interpret these various
connectives? Importantly, we want to be able to interpret propositional formulae 
in terms of sets: this will let us connect back to our earlier goals for 
efficiently representing events and distributions.

One way to interpret a formula is by asking if, for a particular state of the
world, is the formula true? To do this, we can fix an \defn{interpretation} $I : V
\rightarrow \{\true, \false\}$, which is a map that maps any variable $v \in V$
to a truth assignment; intuitively, this interpretation will capture some state 
of the world. For example, in our running example, an interpretation that states 
that it is currently raining and not wet would be:\sidenote{As notation, we will sometimes 
abbreviate $r \mapsto \true$ as an unadorned $r$, and $r \mapsto \false$ as
$\overline{r}$. Additionally, we use the notation $\triangleq$ to denote definitional equality.}
\begin{align}
    I_{ex} \triangleq [r \mapsto \true, w \mapsto \false] \triangleq [r, \overline{w}].
    \label{eq:iex}
\end{align}

Now we can interpret propositional formulae for a particular interpretation $I$.
This will be our formal notion of semantics:
\begin{definition}[Semantics of propositional formulae]  
    An instance $I$ is called a \defn{model} for a formula $\varphi$, written $I
    \models \varphi$, if the following inductive description holds:
\begin{align*}
    I &\models a & \text{ iff } I(a) = \true \\
    I &\models \neg \varphi & \text{ iff } I \not{\models} \varphi, \text{ i.e. it is not the case that } I \models \varphi \\
    I &\models \alpha \land \beta & \text{ iff } I \models \alpha \text{ and } I \models \beta \\
    I &\models \alpha \lor \beta & \text{ iff } I \models \alpha \text{ or } I \models \beta \\
    I &\models \alpha \Rightarrow \beta & \text{ iff } I \not{\models} \alpha \text{ or } I \models \beta \\
    I &\models \alpha \Leftrightarrow \beta & \text{ iff } I \models \alpha, I \models \beta \text{ or }  I \not{\models} \alpha, I \not{\models} \beta. \\
    I &\models \true \\
    I &\not{\models} \false \\
\end{align*}
\end{definition}
Now we have a nice formal description of when a formula holds for a 
given interpretation $I$: this is our first example in the course of a 
formal language semantics. Here is an example:
\begin{align*}
    [x, \overline{y}] \models x \lor y, \text{ since } [x, \overline{y}](x) = \true.
\end{align*}

\newthought{Given a logical formula,} it is often useful to determine \emph{the 
set of all models} for that formula. In some sense, this tells us everything 
there is to know about that formula. A common way to do this is via a 
\defn{truth table}, which lists (1) all possible interpretations for a fixed 
set of propositional variables, and (2) whether or not each interpretation 
models a particular formula. For example, we can give the truth table 
for the formula $x \lor \overline{y}$ as:\marginnote{Truth tables as a way of 
reasoning about propositional formulae were introduced by \citet{wittgenstein2013tractatus}.}


\begin{table}
\centering
 \begin{tabular}{c||c}
    \toprule
    $I$ & $ I \models x \lor y?$ \\
    \midrule 
    $x~y$ & $\true$ \\ 
    $x ~ \overline{y}$ & $\true$ \\ 
    $\overline{x}~y $ & $\true$ \\ 
    $\overline{x} ~ \overline{y}$ & $\false$ \\ 
    \bottomrule
\end{tabular}
\caption{A simple truth table.}
\end{table}

\begin{exercise}[$\star$]
Give the truth table for $(a \Leftrightarrow b) \land (\neg c).$ 
\end{exercise}



\bibliographystyle{plainnat}
\bibliography{../bib}

\end{document}